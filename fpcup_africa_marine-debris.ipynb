{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='center'><img src='imgs/logos.png' alt='Training entities logos' width='80%'></img></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPCUP - Working Group Africa\n",
    "\n",
    "# Training: \n",
    "# Detecting plastic pollution and events of marine debris pollution using Sentinel -2\n",
    "\n",
    "Emanuel Castanho (AIR Centre)\n",
    "\n",
    "25 OCTOBER 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --find-links=https://girder.github.io/large_image_wheels --no-cache GDAL==3.8.0 --quiet\n",
    "# print(\"GDAL checked!\")\n",
    "# !pip install localtileserver==0.7.2 --quiet\n",
    "# print(\"localtileserver checked!\")\n",
    "# !pip install geopandas==0.14.0 --quiet\n",
    "# print(\"geopandas checked!\")\n",
    "# !pip install leafmap==0.27.0 --quiet\n",
    "# print(\"leafmap checked!\")\n",
    "# !pip install scikit-learn==1.1.1 --quiet # To load the model you need the same version\n",
    "# print(\"scikit-learn checked!\")\n",
    "# !pip install pyarrow==13.0.0 --quiet\n",
    "# print(\"pyarrow checked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbextension install --py --symlink --sys-prefix ipyleaflet\n",
    "# !jupyter nbextension enable --py --sys-prefix ipyleaflet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import leafmap\n",
    "from osgeo import gdal\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipyleaflet import CircleMarker, LayerGroup\n",
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basepath as string. Empty for current path.\n",
    "basepath = \"\"\n",
    "\n",
    "# Stack file with ACOLITE Rayleigh-corrected bands and spectral indices.\n",
    "rc_stack = \"S2A_MSI_2022_04_13_08_08_18_T36JUN_stack.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available bands (RC Bands + Spectral Indices) inside stack:\n",
      "{'B01': 1, 'B02': 2, 'B03': 3, 'B04': 4, 'B05': 5, 'B06': 6, 'B07': 7, 'B08': 8, 'B8A': 9, 'B11': 10, 'B12': 11, 'NDVI': 12, 'FAI': 13, 'FDI': 14, 'SI': 15, 'NDWI': 16, 'NRD': 17, 'NDMI': 18, 'BSI': 19}\n"
     ]
    }
   ],
   "source": [
    "# Stack fullpath and name without extension\n",
    "stack_fullpath = os.path.join(basepath, \"data\", rc_stack)\n",
    "stack_name = rc_stack[:-4]\n",
    "\n",
    "# Check available bands and their numbering\n",
    "stack_dataset = gdal.Open(stack_fullpath)\n",
    "stack_bands = {stack_dataset.GetRasterBand(i).GetDescription(): i for i in range(1, stack_dataset.RasterCount+1)}\n",
    "print(\"Available bands (RC Bands + Spectral Indices) inside stack:\")\n",
    "print(stack_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start leafmap and add data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start basemap\n",
    "m = leafmap.Map(location=[31.4710, -29.6108], zoom_start=5)\n",
    "\n",
    "# Add RGB (Red-Green-Blue) layer \n",
    "m.add_raster(stack_fullpath, band=[4, 3, 2], vmin=0, vmax=0.15, layer_name=\"RGB\")\n",
    "\n",
    "# Add NDWI (Normalized Difference Water Index)\n",
    "ndwi_vis = {\"cmap\":\"bwr_r\", \"vmin\":-1, \"vmax\":0.8, \"name\":\"NDWI\"}\n",
    "m.add_raster(stack_fullpath, band=16, cmap=ndwi_vis[\"cmap\"], vmin=ndwi_vis[\"vmin\"], vmax=ndwi_vis[\"vmax\"], layer_name=ndwi_vis[\"name\"])\n",
    "m.add_colormap(cmap=ndwi_vis[\"cmap\"], label=ndwi_vis[\"name\"], vmin=ndwi_vis[\"vmin\"], vmax=ndwi_vis[\"vmax\"], width=4)\n",
    "\n",
    "# Add FDI (Floating Debris Index)\n",
    "fdi_vis = {\"cmap\":\"twilight_shifted\", \"vmin\":0, \"vmax\":0.1, \"name\":\"FDI\"}\n",
    "m.add_raster(stack_fullpath, band=14, cmap=fdi_vis[\"cmap\"], vmin=fdi_vis[\"vmin\"], vmax=fdi_vis[\"vmax\"], layer_name=fdi_vis[\"name\"])\n",
    "m.add_colormap(cmap=fdi_vis[\"cmap\"], label=fdi_vis[\"name\"], vmin=fdi_vis[\"vmin\"], vmax=fdi_vis[\"vmax\"], width=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert stack to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        B01       B02       B03       B04       B05       B06       B07  \\\n",
      "0  0.089779  0.085006  0.066746  0.060497  0.059147  0.057825  0.059238   \n",
      "1  0.089780  0.079840  0.066410  0.060074  0.059147  0.057825  0.059238   \n",
      "2  0.089780  0.080201  0.067641  0.059227  0.058833  0.060110  0.059857   \n",
      "3  0.089780  0.082604  0.067641  0.060074  0.058833  0.060110  0.059857   \n",
      "4  0.089780  0.082243  0.066634  0.059756  0.058833  0.060110  0.059548   \n",
      "\n",
      "        B08       B8A       B11       B12      NDVI       FAI       FDI  \\\n",
      "0  0.055262  0.053458  0.040377  0.033586 -0.045223 -0.001669  0.015881   \n",
      "1  0.055365  0.053458  0.040377  0.033586 -0.040792 -0.001218  0.015983   \n",
      "2  0.054647  0.055092  0.039675  0.034487 -0.040216 -0.001115  0.016138   \n",
      "3  0.053520  0.055092  0.039675  0.034487 -0.057697 -0.002939  0.015010   \n",
      "4  0.052597  0.058461  0.040276  0.035288 -0.063717 -0.003707  0.013452   \n",
      "\n",
      "         SI      NDWI       NRD      NDMI       BSI  \n",
      "0  0.929192  0.094121 -0.005235  0.155645 -0.163367  \n",
      "1  0.931189  0.090704 -0.004709  0.156549 -0.147481  \n",
      "2  0.930937  0.106251 -0.004580  0.158736 -0.153780  \n",
      "3  0.929847  0.116546 -0.006554  0.148558 -0.154213  \n",
      "4  0.930408  0.117727 -0.007159  0.132664 -0.148199  \n"
     ]
    }
   ],
   "source": [
    "# All the stack bands (RC Bands + Spectral Indices) will be Machine Learning (ML) model features\n",
    "ml_model_features = list(stack_bands.keys())\n",
    " \n",
    "# Initiate the loop with B01\n",
    "init_stack_data = stack_dataset.GetRasterBand(1).ReadAsArray()\n",
    "# Reshape as single column\n",
    "stack_data = init_stack_data.reshape(-1,1)\n",
    "\n",
    "# Loop through the other bands\n",
    "for band in ml_model_features[1:]:\n",
    "    # Get data\n",
    "    band_data = stack_dataset.GetRasterBand(stack_bands[band]).ReadAsArray()\n",
    "    band_data_reshaped = band_data.reshape(-1,1)\n",
    "    stack_data = np.concatenate([stack_data, band_data_reshaped], axis=1)\n",
    "\n",
    "# Shape to use in reshape\n",
    "band_shape = init_stack_data.shape\n",
    "\n",
    "# Global dataframe for classification\n",
    "global_cl_df = pd.DataFrame(stack_data, columns=ml_model_features)\n",
    "\n",
    "# Dataframe for classification, without not a numbers. RF model does not work with NaN\n",
    "no_nans_cl_df = global_cl_df.dropna(axis=0, how='any')\n",
    "\n",
    "print(no_nans_cl_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Random Forest ML model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(ccp_alpha=0, class_weight='balanced_subsample',\n",
      "                       max_depth=20, min_impurity_decrease=0,\n",
      "                       min_weight_fraction_leaf=0, n_estimators=125, n_jobs=-1,\n",
      "                       oob_score=True, random_state=5)\n"
     ]
    }
   ],
   "source": [
    "# The trained model is stored in a pickle file\n",
    "rf_model_fullpath = glob.glob(os.path.join(basepath, \"data\", \"MARIDA_RF-model\", \"*.pkl\"))[0]\n",
    "rf_model = pkl.load(open(rf_model_fullpath, 'rb'))\n",
    "print(rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": # Brokenpipe bug is caused by multiprocessing on Jupyter, does not affect the results\n",
    "    # Dataframe of 0's to store the classification results\n",
    "    cl_results_struct_df = pd.DataFrame(0, index=range(0, len(global_cl_df.index)), columns=['ClassNum'])\n",
    "\n",
    "    # If dataframe for classification without NaNs is empty, then the final classification is only 0.  \n",
    "    if len(no_nans_cl_df.index) == 0:\n",
    "        cl_results_flat = np.array(cl_results_struct_df).flatten()\n",
    "        cl_results_reshape = cl_results_flat.reshape(band_shape)\n",
    "    else:\n",
    "        # RF Classification\n",
    "        cl_results = rf_model.predict(no_nans_cl_df)\n",
    "\n",
    "        # Index results, construct final dataframe and reshape\n",
    "        cl_results_indexed = pd.DataFrame(cl_results, index=no_nans_cl_df.index, columns=['ClassNum'])\n",
    "        cl_results_df = cl_results_indexed.combine_first(cl_results_struct_df)\n",
    "        cl_results_flat = np.array(cl_results_df).flatten()\n",
    "        cl_results_reshape = cl_results_flat.reshape(band_shape)\n",
    "\n",
    "    # Save classification map\n",
    "    sc_map_fullpath = os.path.join(basepath, \"processing\", \"scmap.tif\")\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    sc_raster = driver.Create(sc_map_fullpath, stack_dataset.RasterXSize, stack_dataset.RasterYSize, 1, gdal.GDT_Byte)\n",
    "    sc_raster.SetProjection(stack_dataset.GetProjectionRef())\n",
    "    sc_raster.SetGeoTransform(stack_dataset.GetGeoTransform())\n",
    "    sc_raster_band = sc_raster.GetRasterBand(1)\n",
    "    sc_raster_band.WriteArray(cl_results_reshape)\n",
    "    sc_raster = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add classification to leafmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scene classification map\n",
    "# Color palette:\n",
    "# 0- No Data - NaNs\n",
    "# 1- Marine Debris - Floating plastics or other polymers, mixed anthropogenic debris\n",
    "# 2- Dense Sargassum - Dense floating Sargassum macroalgae\n",
    "# 3- Sparse Sargassum - Sparse floating Sargassum macroalgae\n",
    "# 4- Natural Organic Material - Vegetation & Wood\n",
    "# 5- Ship - Sailing & Anchored Vessels\n",
    "# 6- Clouds - Clouds including thin Clouds\n",
    "# 7- Marine Water SC - Marine Water Super Class: Clear Water, Wakes, CloudS, Waves and MixWater\n",
    "# 8- Sediment-Laden Water - High-Sediment river discharges with brown colour\n",
    "# 9- Foam - Foam recorded at river fronts or coastal wave breaking area\n",
    "# 10- Turbid Water - Turbid waters close to coastal areas\n",
    "# 11- Shallow Water - Coastal waters, including coral reefs and submerged vegetation\n",
    "\n",
    "cl_vis = {\"cmap\":[\"#ffffff\", \"#ff0000\", \"#008000\", \"#32cd32\", \"#b22222\", \"#ffa500\", \"#c0c0c0\", \"#000080\", \"#ffd700\", \"#800080\", \"#bdb76b\", \"#00ced1\"], \"vmin\":0, \"vmax\":11, \"name\":\"Classification\"}\n",
    "m.add_raster(sc_map_fullpath, band=1, cmap=cl_vis[\"cmap\"], vmin=cl_vis[\"vmin\"], vmax=cl_vis[\"vmax\"], layer_name=cl_vis[\"name\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Marine Debris pixels center coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scene classification GeoTIFF to XYZ\n",
    "sc_map_raster = gdal.Open(sc_map_fullpath)\n",
    "xyz_fullpath = os.path.join(basepath, \"processing\", \"scmap.xyz\")\n",
    "xyz_raster = gdal.Translate(xyz_fullpath, sc_map_raster)\n",
    "\n",
    "# Close rasters\n",
    "sc_map_raster = None\n",
    "xyz_raster = None\n",
    "\n",
    "# Convert XYZ to Feather\n",
    "xyz_df = pd.read_csv(xyz_fullpath, sep=\" \", header=None)\n",
    "xyz_df.columns = [\"CenterX\", \"CenterY\", \"Value\"]\n",
    "feather_fullpath = os.path.join(basepath, \"processing\", \"scmap.feather\")\n",
    "xyz_df.to_feather(feather_fullpath)\n",
    "\n",
    "# Delete intermediate XYZ file\n",
    "os.remove(xyz_fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that converts Sentinel-2 CRS to EPSG4326 depending on Tile\n",
    "def s2_coord_converter(row):\n",
    "    '''\n",
    "    This function converts UTM coordinates to EPSG:4326. It uses Sentinel-2 tile information.\n",
    "    https://sentinels.copernicus.eu/documents/247904/685211/Sentinel-2-Products-Specification-Document.pdf/fb1fc4dc-12ca-4674-8f78-b06efa871ab9\n",
    "    \n",
    "    Inputs: row - Row of dataframe, must contain: Tile, CenterX and CenterY.\n",
    "    Outputs: (lon, lat) - Tuple with longitude and latitude pair.\n",
    "    '''\n",
    "    # First letter of tile code\n",
    "    if row[\"Tile\"][2] in list(map(chr, range(67, 78))):\n",
    "        # South C-M\n",
    "        pos = \"327\"\n",
    "    elif row[\"Tile\"][2] in list(map(chr, range(78, 89))):\n",
    "        # North N-X\n",
    "        pos = \"326\"\n",
    "    else:\n",
    "        # Undefined\n",
    "        pos = None\n",
    "\n",
    "    # Conversion of coordinates. EPSG + South or North + first 2 digits of tile code\n",
    "    in_crs = \"epsg:\" + pos + row[\"Tile\"][0:2]\n",
    "    out_crs = \"epsg:4326\"\n",
    "    trans = Transformer.from_crs(in_crs, out_crs)\n",
    "    x, y = row[\"CenterX\"], row[\"CenterY\"]\n",
    "    lat, lon = trans.transform(x, y)\n",
    "    \n",
    "    return (lon, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CenterX  CenterY  Value   Tile  CenterLon  CenterLat\n",
      "1351    357135  6733095      1  36JUN  31.525806 -29.523608\n",
      "23690   356535  6732965      1  36JUN  31.519599 -29.524712\n",
      "29043   358375  6732935      1  36JUN  31.538577 -29.525193\n",
      "29044   358385  6732935      1  36JUN  31.538680 -29.525194\n",
      "29047   358415  6732935      1  36JUN  31.538989 -29.525197\n"
     ]
    }
   ],
   "source": [
    "# Filter only MD and convert coordinate system\n",
    "feather_df = pd.read_feather(feather_fullpath)\n",
    "feather_md_df = feather_df[feather_df.Value==1]\n",
    "feather_md_df[\"Tile\"] = stack_name.split(\"_\")[8][1:]\n",
    "feather_md_df[\"CenterLon\"], feather_md_df[\"CenterLat\"] = zip(*(feather_md_df.apply(lambda row: s2_coord_converter(row), axis=1)))\n",
    "print(feather_md_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot suspected MD locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suspected Marine Debris as black dots\n",
    "markers = []\n",
    "for idx, row in feather_md_df.iterrows():\n",
    "    marker = CircleMarker(location=[row[\"CenterLat\"], row[\"CenterLon\"]], radius=1, color=\"black\", fill_color=\"black\", opacity=1)\n",
    "    markers.append(marker)\n",
    "layer_group = LayerGroup(layers=markers, name=\"Suspected MD\")\n",
    "m.add_layer(layer_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show final map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f969fdceff048c6a5efabc0ee33119a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-29.607231292818643, 31.473917956217676], controls=(ZoomControl(options=['position', 'zoom_in_textâ€¦"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
